{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Agency Swarm Cookbook","text":"<p>An open scource project created by VRSEN AI</p>"},{"location":"#introduction","title":"Introduction","text":"<ul> <li>What is Agency Swarm?</li> </ul> <p>Agency Swarm is an open-source agent orchestration framework designed to automate and streamline AI development processes. Leveraging the power of the OpenAI Assistants API, it enables the creation of a collaborative swarm of agents (Agencies), each with distinct roles and capabilities. This framework aims to replace traditional AI development methodologies with a more dynamic, flexible, and efficient agent-based system.</p> <ul> <li> <p>Goal of the project Allow people to create their agencies with AI and build a self expanding system, that grows with each contribution</p> </li> <li> <p>Agency Swarm vs Other Frameworks</p> </li> </ul> <p>Differences between agency swarm and Autogen.</p>"},{"location":"#differences-between-autogen-and-agency-swarm","title":"Differences between Autogen and Agency swarm.","text":"<p>AutoGen recreated from scratch using just five or six functions with the new OpenAI Assistants API. Here is their famous example, featuring a chart of YTD, Meta, and Tesla stock prices, that was made by this system, consisting of just 2 agents: a coding assistant and a user proxy agent. But the best part is that this system is much more controllable and customizable, which means unlike autogen, it is actually deployable in production.</p> <p>Agency Swarm does not write prompts for you - It includes automatic type checking with instructor - It is build on top of the latest OpenAI Assistants API (OpenAI is extremely likely to include more exciting features soon) - It allows you to easily define communication flows</p>"},{"location":"#quick-start","title":"Quick Start","text":"<ul> <li>Short description of how to install and create a simple agency with simple tools</li> </ul>"},{"location":"#assistant-api-working","title":"Assistant API  working","text":"<p>The Assistant API working is quite different from the previous chat completions approach. In this new api, there are threads that represent conversations, messages that represent individual messages within the threads, and agents that execute the threads to generate new messages. I know it can be confusing. So, the general process is as follows: </p> <ol> <li>First, you have to create an agent. </li> <li>Then, you have to create a thread. </li> <li>Next, you have to add a message to the thread. </li> <li>After that, you have create a run for this thread and agent ids.  The big change here is that runs execute asynchronously, so you have to continuously check for the updates until the run is finished. </li> <li>And finally, once that's done, if the run is in completed status, the run goes into requires_action or completed status. </li> </ol>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install agency-swarm\n</code></pre>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Set Your OpenAI Key:</li> </ol> <pre><code>from agency_swarm import set_openai_key\nset_openai_key(\"YOUR_API_KEY\")\n</code></pre>"},{"location":"#advanced-tools","title":"Advanced Tools","text":"<ul> <li>Brief explanation on how to create tools with\u00a0Instuctor</li> <li>Some tool examples would be cool</li> <li> <p>How to use ToolFactory class to convert openai schemas into tools or import langchain tools with examples</p> </li> <li> <p>Create Tools: Define your custom tools with\u00a0Instructor:</p> </li> </ul> <p>[github] Convert from OpenAPI schemas:</p>"},{"location":"#agent-roles","title":"Agent Roles:","text":"<p>Start by defining the roles of your agents. For example, a CEO agent for managing tasks and a developer agent for executing tasks.</p> <pre><code>from agency_swarm import Agent\n\nceo = Agent(name=\"CEO\",\n            description=\"Responsible for client communication, task planning and management.\",\n            instructions=\"You must converse with other agents to ensure complete task execution.\", # can be a file like ./instructions.md\n            files_folder=\"./files\", # files to be uploaded to OpenAI\n            schemas_folder=\"./schemas\", # OpenAPI schemas to be converted into tools\n            tools=[MyCustomTool, LangchainTool])\n</code></pre> <p>Import from existing agents:</p>"},{"location":"page1/","title":"Google Colab Guide","text":""},{"location":"page1/#assistant-api-working","title":"Assistant API working","text":"<p>The Assistant API is quite different from the previous chat completions approach. In this new Api, there are threads that represent conversations, messages that represent individual messages within the threads, and agents that execute the threads to generate new messages. It can be a bit confusing. So, the general process is as follows:  1. Create an agent.  2. Create a thread.  3. Add a message to the thread.  4. After that, you have to create a run for this thread and agent ids.  The big change here is that runs execute asynchronously, so you have to continuously check for the updates until the run is finished.  5. Once that's done, if the run is in completed status, the run goes into requires_action or completed status. </p> <p>If it is, completed it means that you safely retrieve the thread with the new assistant message, when if it in requires_action, it means that you have to run your function, pass the output back and run the thread again. </p> <p>Get completion. But to simplify the entire process and make it familiar for all of us who are used to the previous version of the OpenAI API, I have created a function called get_completion that essentially goes through all the steps that I have just described until the final assistant response is received.  Check out the doc string for more details, because you might wanna copy this function for your own projects.</p> <p>{get completion} </p>"},{"location":"page1/#coding-agent","title":"Coding Agent","text":"<p>Now let's go ahead and create our first code assistant agent, which will be responsible for generating and executing code locally. We'll begin with the tools that this agent will utilize, defined with the instructor library. </p> <p>The first tool is <code>ExecutePyFile</code>, class ExecutePyFile(OpenAISchema): <pre><code>\u00a0 \u00a0 \"\"\"Run existing python file from local disc.\"\"\"\n\n\u00a0 \u00a0 file_name: str = Field(\n\n\u00a0 \u00a0 \u00a0 \u00a0 ..., description=\"The path to the .py file to be executed.\"\n\n\u00a0 \u00a0 )\n</code></pre> \u00a0will run an existing Python file from the disk, taking the file name as a parameter. </p>"},{"location":"page1/#capturing-outputs-and-errors","title":"Capturing outputs and errors","text":"<p>In the <code>run</code> function inside this model, we'll execute the file with Python 3 using the subprocess module and capture any outputs or errors.  <pre><code>\u00a0def run(self):\n\n\u00a0 \u00a0 \u00a0 \"\"\"Executes a Python script at the given file path and captures its output and errors.\"\"\"\n\n\u00a0 \u00a0 \u00a0 try:\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 result = subprocess.run(\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ['python3', self.file_name],\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 text=True,\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 capture_output=True,\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 check=True\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 )\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return result.stdout\n\n\u00a0 \u00a0 \u00a0 except subprocess.CalledProcessError as e:\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return f\"An error occurred: {e.stderr}\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\n</code></pre> Our second function, named <code>File</code>, serves to write a file onto the disk for later execution. </p> <p>Accurate function descriptions are crucial here; and as you can see by using the {instructor} library, you can define them directly in the docstrings or the field descriptions associated with each specific parameter, which is extremely convenient. <pre><code>class File(OpenAISchema):\n\n\u00a0 \u00a0 \"\"\"\n\n\u00a0 \u00a0 Python file with an appropriate name, containing code that can be saved and executed locally at a later time. This environment has access to all standard Python packages and the internet.\n\n\u00a0 \u00a0 \"\"\"\n\n\u00a0 \u00a0 chain_of_thought: str = Field(...,\n\n\u00a0 \u00a0 \u00a0 \u00a0 description=\"Think step by step to determine the correct actions that are needed to be taken in order to complete the task.\")\n\n\u00a0 \u00a0 file_name: str = Field(\n\n\u00a0 \u00a0 \u00a0 \u00a0 ..., description=\"The name of the file including the extension\"\n\n\u00a0 \u00a0 )\n\n\u00a0 \u00a0 body: str = Field(..., description=\"Correct contents of a file\")\n\n\n\n\u00a0 \u00a0 def run(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 with open(self.file_name, \"w\") as f:\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 f.write(self.body)\n\n\n\n\u00a0 \u00a0 \u00a0 \u00a0 return \"File written to \" + self.file_name\n</code></pre></p>"},{"location":"page1/#chain-of-thought","title":"Chain of thought","text":"<p>We will also add an additional parameter 'chain of thought'. This is another ingenious technique introduced by Jason Liu. This parameter forces the model to map out each action, step by step before, proceeding with the function execution itself. This increases accuracy.</p> <p>Next, we'll add both of these functions into an array to be used later in our get completion function and create our code assistant using the new beta assistants API. </p> <pre><code>from openai import OpenAI\n\nclient = OpenAI(api_key=openai.api_key)\n\n\n\ncode_assistant_funcs = [File, ExecutePyFile]\n\n\n\ncode_assistant = client.beta.assistants.create(\n\n\u00a0 name='Code Assistant Agent',\n\n\u00a0 instructions=\"As a top-tier programming AI, you are adept at creating accurate Python scripts. You will properly name files and craft precise Python code with the appropriate imports to fulfill the user's request. Ensure to execute the necessary code before responding to the user.\",\n\n\u00a0 model=\"gpt-4-1106-preview\",\n\n\u00a0 tools=[{\"type\": \"function\", \"function\": File.openai_schema},\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0{\"type\": \"function\", \"function\": ExecutePyFile.openai_schema},]\n\n)\n</code></pre>"},{"location":"page1/#design","title":"Design","text":"<p>This system is designed by following a typical Cubernetes cluster architecture, where the user proxy agent is essentially acting as a load balancer that distributes requests to specialized individual agents and converses with them until the task is executed. </p>"},{"location":"page1/#tools","title":"Tools","text":"<p>The only tool that the user proxy agent will need is a sendMessage tool to send messages to other agents.  It has two parameters: a recipient and a message. The run call in this function actually calls our previous method, getCompletion, with a separate thread for each agent, making our system sort of recusrsive. I say sort of because it has only one level of recursion, after the main loop that also uses the getCompletion function. </p> <p>To ensure that our proxy agent has a separate conversation with each of the other agents in the group chat, we will store separate threads for each agent in a global object called agents_and_threads. </p> <pre><code>agents_and_threads = {\n\n\u00a0 \u00a0 \"code_assistant\": {\n\n\u00a0 \u00a0 \u00a0 \u00a0 \"agent\": code_assistant,\n\n\u00a0 \u00a0 \u00a0 \u00a0 \"thread\": None,\n\n\u00a0 \u00a0 \u00a0 \u00a0 \"funcs\": code_assistant_funcs\n\n\u00a0 \u00a0 }\n\n}\n</code></pre>"},{"location":"page1/#instructions-user-proxy-agent","title":"Instructions User proxy agent","text":"<p>Finally, we can define the user proxy agent itself with some instructions. The most important part here is that the user proxy agent must maintain ongoing communication with other agents until the task is completed. This parameter has a huge impact on the behaviour of the whole system, so definitely make sure to play around with that. </p> <p>To launch this system, simply create a new thread and start an infinite loop that prompts for a user message, gets a completion from the user proxy agent and prints a response. Now we are ready to test. </p> <pre><code>thread = client.beta.threads.create()\n\nwhile True:\n\n\u00a0 user_message = input(\"User: \")\n\n\n\n\u00a0 message = get_completion(user_message, user_proxy, user_proxy_tools, thread)\n\n\n\n\u00a0 wprint(f\"\\033[34m{user_proxy.name}: \", message,'\\033[0m')\n</code></pre>"},{"location":"page1/#result","title":"Result","text":"<p>The user proxy agent immediately calls the code agent with a given task.  After the code assistant agent writes the code to the file, it executes and returns the current date to the user proxy assistant, which then prints it for us below. So in this conversation, the user proxy agent converses with other agents through the send message function. Basically when it needs to chat with another agent, it calls this function with the message, which the other agent than receives as the user message. After the other agent responds, we pass it back as the output of the send message function. This allows for a more natural conversation flow, where the user proxy agent can chat with the other agents as much as needed directly from the main chat with the user. Let's try to run the second question. Compare the year-to-date gain for Meta and Tesla. Now the user proxy agent immediately asks the code assistant to provide the YTD gain, and then the code assistant proceeds with creating the chain of thought prompt and writing the code itself. As you can see, it gets it on the first try and returns the actual numbers using the yFinance library. </p> <p>For the final question let s ask the user proxy to plot the stock price change and save it to the stockpriceytd.png file. After the Code Assistant executes the necessary code, the User Proxy confirms that the file has been successfully saved. You can verify this by browsing the files on the left. As you can see, the resulting graph looks exactly like the one generated by AutoGen. However, our system actually did in far less tokens wasted. </p> <p>Then, after running all the cells again, run the main loop, and your second task execution assistant should now be operational. In conclusion, the best thing about creating custom agent swarms with the assistants API is that they're actually usable in production. Unlike other multi-agent systems, here you have complete control over the creation of new agents and tools. You can easily add any guardrails for you specific use case or even implement any custom logic, making this system easily steerable and adaptable. For instance, I decided to design this example with the Single Responsibility Principle in mind. This is a common practice for building scalable systems, and it implies that each component should have only one specific responsibility, which allows for easy addition of more components or replacement of the existing ones in case of any errors.</p>"},{"location":"page2/","title":"Examples","text":""},{"location":"page2/#web-browsing-agent","title":"Web browsing Agent","text":"<p>Example From The Video Testing oai-widget.com</p> <p><pre><code>from agency_swarm import set_openai_key\nset_openai_key(\"YOUR_OPENAI_API_KEY\")\n</code></pre> <pre><code>from agency_swarm.agents.browsing import BrowsingAgent\nfrom agency_swarm import Agency, Agent\nbrowsing_agent = BrowsingAgent()\nqa_manager = Agent(name=\"QA Manager\",\n            description=\"The QA Manager Agent is an advanced digital entity designed to oversee and enhance the quality of processes for our SaaS product.\",\n            instructions=\"As a Quality Assurance (QA) Manager, your role involves direct interaction and oversight of the BrowsingAgent's operations. Your primary duty is to guarantee that the user's task is comprehensively and accurately completed. Achieve this by methodically issuing each step of the task as a distinct message to the BrowsingAgent. It's crucial to confirm the successful execution of one step before advancing to the next. This procedure forms part of an integration test, which will be conducted in a live production environment. Importantly, ensure to provide the BrowsingAgent with the actual credentials related to the task, enabling authentic testing scenarios.\")\nagency = Agency([qa_manager,\n                 [qa_manager, browsing_agent]])\n</code></pre></p> <pre><code>demo = agency.demo_gradio(height=700) # reload the notebook each time you run this cell\n</code></pre>"},{"location":"page3/","title":"Improvements","text":"<p>There are a few things that you can still improve. </p> <p>First of all, the current system does not support conversations between the agents that execute the tasks. It only supports the conversation between the user proxy with these agents. This is not necessarily a bad thing; however, because this improves the overall steerability of the system and helps to prevent infinite loops. However, you can easily adjust this, by adding more threads into the agent_and_threads object and also allowing other agents to use the sendMessage function. </p> <p>Second, sometimes, it feels like the user proxy agent doesn't fully understand the instructions. I've experimented with the prompt for a bit, but it could certainly use some improvement. And third, as I said before, you could actually make a tool for the user proxy agent that would allow it to create other agents and tools. If you actually manage to do this, I believe it could lead to exponential growth and a complete humanity extinction in the next few months. Now, adding new agents to this system is pretty straightforward. First, create the tools the agent will use with the Pydantic schemas using Instructor. You can simply copy the code for the code assistant agent, replacing any tools as needed. Then, add this new agent to the agents and threads object and create the assistant using the new beta assistants API. </p> <p>You can also include out-of-the-box tools like web browsing and code interpreter, but note that the code interpreter can't execute local files and has limitations. After creating your new agent, add its name to the recipient literal in the send message function and describe what this agent should do in the property description. </p>"},{"location":"page3/#future-enhancements","title":"Future Enhancements","text":"<p>Creation of agencies that can autonomously create other agencies.- DONE  Asynchronous communication and task handling.                    - DONE  Inter-agency communication for a self-expanding system</p>"},{"location":"page4/","title":"Contributing to Agency Swarm","text":"<p>Each agent or tool you add to Agency Swarm will automatically be available for import by the Genesis Swarm, which will help us create an exponentially larger and smarter system.</p> <p>This document provides guidelines for contributing new agents and tools to the framework.</p>"},{"location":"page4/#folder-structure-for-tools","title":"Folder Structure for Tools","text":"<p>Tools should be added in the agency_swarm/tools/{category}/ directory like below. Each tool should be in its specific category folder like coding, browsing, investing etc.</p> <p>Your tool file should be named YourNewTool.py. Tests should be added in agency_swarm/tests/test_tools.py. Directory structure for a new tool:</p> <pre><code>agency_swarm/tools/your-tool-category/\n\u2502\n\u251c\u2500\u2500 YourNewTool.py          # The main agent class file\n\u2514\u2500\u2500 __init__.py             # Make sure to import your tool here\n</code></pre>"},{"location":"page4/#adding-tests-for-your-tools","title":"Adding Tests For Your Tools","text":"<p>For each tool, please add the following test case in agency_swarm/tests/test_tools.py: <pre><code>    def test_my_tool_example(self):\n        output = MyCustomTool(query='John Doe').run()\n        self.assertFalse(\"error\" in output.lower())\n</code></pre></p>"},{"location":"page4/#folder-structure-for-agents","title":"Folder Structure for Agents","text":"<p>Agents should be placed in agency_swarm/agents/{category}/ directory. Each agent should have its dedicated folder named AgentName like below. Make sure to use CamelCase for the agent name and the folder. <pre><code>agency_swarm/agents/your-agent-category/AgentName/\n\u2502\n\u251c\u2500\u2500 agency_manifesto.md or .txt # Agency's guiding principles (created if not exists)\n\u2514\u2500\u2500 AgentName/                  # Directory for the specific agent\n    \u251c\u2500\u2500 files/                  # Directory for files that will be uploaded to openai (if any)\n    \u251c\u2500\u2500 schemas/                # Directory for OpenAPI schemas to be converted into tools (if any)\n    \u251c\u2500\u2500 AgentName.py            # The main agent class file\n    \u251c\u2500\u2500 __init__.py             # Initializes the agent folder as a Python package\n    \u2514\u2500\u2500 instructions.md         # Instruction document for the agent\n</code></pre></p>"},{"location":"page4/#creating-an-agent","title":"Creating an Agent","text":"<p>Follow the structure below in your AgentName.py as a guideline. All tools (except schemas) should be imported in AgentName.py from the agency_swarm/tools/... folder. <pre><code>from agency_swarm import Agent\nfrom agency_swarm.tools.example import ExampleTool\n\nclass AgentName(Agent):\n    def __init__(self, **kwargs):\n        # Initialize tools in kwargs if not present\n        if 'tools' not in kwargs:\n            kwargs['tools'] = []\n        # Add required tools\n        kwargs['tools'].extend([ExampleTool])\n\n        # Set instructions\n        kwargs['instructions'] = \"./instructions.md\"\n\n        # Add more kwargs as needed\n\n        # Initialize the parent class\n        super().__init__(**kwargs)\n</code></pre></p> <p>Thank you for contributing to Agency Swarm! Your efforts help us build a more robust and versatile framework.</p>"}]}